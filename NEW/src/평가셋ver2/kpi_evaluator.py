import os
import pandas as pd
import numpy as np
import openai
import asyncio
import json
from dotenv import load_dotenv
from sklearn.metrics.pairwise import cosine_similarity
from collections import Counter

# â˜… [ì—°ê²°] ë‹˜ì´ ë§Œë“  ë­ê·¸ë˜í”„ ì—”ì§„ ê°€ì ¸ì˜¤ê¸°
from my_agent import run_agent_bridge

# 1. ì„¤ì • ë¡œë“œ
load_dotenv()
client = openai.Client(api_key=os.getenv("OPENAI_API_KEY"))

# ---------------------------------------------------------
# [KPI Class] 4ëŒ€ ê´€ì  í†µí•© í‰ê°€ê¸°
# ---------------------------------------------------------
class UltimateEvaluator:
    def __init__(self):
        self.client = client
        self.all_recommendations = [] # ë‹¤ì–‘ì„± ê³„ì‚°ìš© (ëª¨ë“  ì¶”ì²œ ê³¡ ì œëª© ì €ì¥)

    # --- ë„êµ¬: JSON ë¬¸ìì—´ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì„ë² ë”©ìš©) ---
    def _extract_content_for_embedding(self, json_str):
        try:
            # ë§ˆí¬ë‹¤ìš´ ì œê±°
            clean_str = json_str.replace("```json", "").replace("```", "").strip()
            data = json.loads(clean_str)
            
            # ë¦¬ìŠ¤íŠ¸ë©´ ì²« ë²ˆì§¸ ì¶”ì²œ ê³¡ì˜ ì´ìœ ì™€ ì œëª©ë§Œ ì¶”ì¶œ
            if isinstance(data, list) and len(data) > 0:
                item = data[0]
                reason = item.get('recommendation_meta', {}).get('reasoning', '')
                title = item.get('track_info', {}).get('track_title', '')
                artist = item.get('track_info', {}).get('artist_name', '')
                return f"{reason} {title} {artist}"
            return clean_str # íŒŒì‹± ì‹¤íŒ¨í•˜ë©´ í†µì§¸ë¡œ ë°˜í™˜
        except:
            return json_str

    # --- 1. ì •í™•ì„± (Accuracy): Hybrid (Math + LLM) ---
    def evaluate_accuracy(self, row, output):
        # (A) ìˆ˜í•™ì : ì„ë² ë”© ìœ ì‚¬ë„ (Topic Check)
        try:
            criteria = row['Evaluation Criteria']
            # JSON ì „ì²´ê°€ ì•„ë‹ˆë¼ í•µì‹¬ ë‚´ìš©(ì´ìœ +ê³¡ëª…)ë§Œ ë°œë¼ë‚´ì„œ ì„ë² ë”©
            content_to_embed = self._extract_content_for_embedding(output)
            
            resp = self.client.embeddings.create(input=[criteria, content_to_embed], model="text-embedding-3-small")
            score_math = cosine_similarity([resp.data[0].embedding], [resp.data[1].embedding])[0][0] * 100
        except Exception as e:
            print(f"  Warning(Math): {e}")
            score_math = 0

        # (B) ë…¼ë¦¬ì : LLM Judge (Context & Genre Check)
        system_prompt = """
        You are a strict 'Music Recommendation Auditor'.
        Compare the Agent's JSON Output with the Evaluation Criteria.
        
        [Criteria]
        1. Context Match: Does the song fit the Location/Goal? (e.g., No loud music in Library)
        2. Preference Match: Does it respect User's Genre preference?
        3. Conflict Resolution: If Context and Preference clash (e.g., Metal in Library), did the agent find a smart compromise?
        
        Score 0-100. Return ONLY the integer score.
        """
        
        user_msg = f"""
        [Context] {row['Location']} / {row['Goal']} (Decibel: {row['Decibel']})
        [User Pref] {row['User Pref']}
        [Evaluation Criteria] {row['Evaluation Criteria']}
        
        [Agent Output]
        {output}
        
        Score:
        """
        try:
            resp = self.client.chat.completions.create(
                model="gpt-4o", 
                messages=[{"role":"system","content":system_prompt}, {"role":"user","content":user_msg}],
                temperature=0
            )
            # ìˆ«ìë§Œ ì¶”ì¶œ
            score_llm = int(''.join(filter(str.isdigit, resp.choices[0].message.content)))
        except:
            score_llm = 0
            
        return score_math, score_llm

    # --- 2. ì•ˆì •ì„± (Reliability): Success Rate ---
    def check_reliability(self, output):
        # ë¹ˆ ê°’ì´ ì•„ë‹ˆê³ , ì—ëŸ¬ ë©”ì‹œì§€ê°€ ì—†ìœ¼ë©°, 'track_info' í‚¤ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        if output and len(output) > 10 and "error" not in output.lower():
            if "track_info" in output: # JSON í‚¤ ì²´í¬
                return 1 # Success
        return 0 # Fail

    # --- 4. ë‹¤ì–‘ì„± (Diversity): ì „ì²´ ì™„ë£Œ í›„ ê³„ì‚° ---
    def add_to_diversity_pool(self, output):
        try:
            # ê³¡ ì œëª©ë§Œ ì¶”ì¶œí•´ì„œ ì €ì¥
            clean_str = output.replace("```json", "").replace("```", "").strip()
            data = json.loads(clean_str)
            if isinstance(data, list):
                for item in data:
                    title = item.get('track_info', {}).get('track_title', 'unknown')
                    self.all_recommendations.append(title)
        except:
            pass # íŒŒì‹± ì—ëŸ¬ë‚˜ë©´ ë‹¤ì–‘ì„± ì§‘ê³„ ì œì™¸

    def calculate_final_diversity(self):
        # ì¤‘ë³µë˜ì§€ ì•Šì€ ì¶”ì²œ ê²°ê³¼ì˜ ë¹„ìœ¨ (Unique / Total)
        if not self.all_recommendations: return 0
        unique_count = len(set(self.all_recommendations))
        total_count = len(self.all_recommendations)
        return (unique_count / total_count) * 100

# ---------------------------------------------------------
# [Main Loop] ì‹¤í–‰ (ë¹„ë™ê¸°)
# ---------------------------------------------------------
async def main():
    # 1. í‰ê°€ì…‹ ë¡œë“œ
    csv_file = "evaluation_set_v2_criteria.csv"
    if not os.path.exists(csv_file):
        print(f"âŒ '{csv_file}' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. í‰ê°€ì…‹ ìƒì„± ì½”ë“œë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return

    df = pd.read_csv(csv_file)
    evaluator = UltimateEvaluator()
    results = []
    
    print(f"ğŸš€ í‰ê°€ ì‹œì‘... (ì´ {len(df)}ê°œ ì¼€ì´ìŠ¤)")
    print("-" * 60)

    # 2. ë°˜ë³µ ì‹¤í–‰
    for idx, row in df.iterrows():
        # Bridgeì— ë„£ì„ ì…ë ¥ê°’ êµ¬ì„±
        inputs = {
            "location": row['Location'],
            "decibel": row['Decibel'],
            "goal": row['Goal'],
            "user_pref": row['User Pref'],
            # CSVì— 'User Artist' ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ None ì²˜ë¦¬
            "user_artist": row['User Artist'] if 'User Artist' in row else None
        }
        
        print(f"â–¶ [{idx+1}/{len(df)}] ID {row['ID']} ({row['Location']}/{row['Goal']}) í‰ê°€ ì¤‘...")
        
        # (1) ë­ê·¸ë˜í”„ ì—”ì§„ ì‹¤í–‰ (await í•„ìˆ˜!)
        try:
            output = await run_agent_bridge(inputs)
        except Exception as e:
            print(f"  âŒ Engine Error: {e}")
            output = '{"error": "Runtime Error"}'

        # (2) ë‹¤ì–‘ì„± í’€ ì €ì¥
        evaluator.add_to_diversity_pool(output)
        
        # (3) KPI ì¸¡ì •
        score_math, score_llm = evaluator.evaluate_accuracy(row, output) # ì •í™•ì„±
        is_success = evaluator.check_reliability(output) # ì•ˆì •ì„±
        
        # (4) í†µí•© ì ìˆ˜ (LLM 70% + Math 30%)
        final_score = (score_math * 0.3) + (score_llm * 0.7)

        results.append({
            "ID": row['ID'],
            "Context": f"{row['Location']}-{row['Goal']}",
            "Output_Snippet": output[:50] + "...", # ê²°ê³¼ ìš”ì•½
            "KPI_Math": round(score_math, 1),
            "KPI_Logic": score_llm,
            "KPI_Success": is_success,
            "Final_Score": round(final_score, 1)
        })
        
        print(f"  ã„´ ê²°ê³¼: {final_score:.1f}ì  (Logic:{score_llm} / Math:{score_math:.0f}) | Success: {is_success}")

    # 3. ìµœì¢… ì§‘ê³„ ë° ì €ì¥
    diversity_score = evaluator.calculate_final_diversity()
    result_df = pd.DataFrame(results)
    
    print("\n" + "="*30)
    print("ğŸ†  ULTIMATE KPI REPORT  ğŸ†")
    print("="*30)
    
    if len(result_df) > 0:
        avg_success = result_df['KPI_Success'].mean() * 100
        avg_logic = result_df['KPI_Logic'].mean()
        avg_math = result_df['KPI_Math'].mean()
        
        print(f"1. ì‹œìŠ¤í…œ ì•ˆì •ì„± (Success Rate) : {avg_success:.1f}%")
        print(f"2. í‰ê·  ì •í™•ë„ (Logic + Math) : {avg_logic:.1f} (Logic) + {avg_math:.1f} (Math)")
        print(f"3. ì¶”ì²œ ë‹¤ì–‘ì„± (Diversity)    : {diversity_score:.1f}%")
        
        # CSV ì €ì¥
        result_df.to_csv("final_kpi_report.csv", index=False, encoding="utf-8-sig")
        print(f"\nâœ… ìƒì„¸ ê²°ê³¼ê°€ 'final_kpi_report.csv'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("ê²°ê³¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    asyncio.run(main())