import os
import json
import asyncio
import logging
import pandas as pd
import numpy as np
import spotipy
from spotipy.oauth2 import SpotifyClientCredentials
from datetime import datetime
from sklearn.metrics.pairwise import cosine_similarity
from dotenv import load_dotenv
from openai import AsyncOpenAI

# â˜… [ì—°ê²°] ë­ê·¸ë˜í”„ ì—”ì§„ ê°€ì ¸ì˜¤ê¸°
from my_agent import run_agent_bridge

# --------------------------------------------------------------------------
# 0. í™˜ê²½ ì„¤ì •
# --------------------------------------------------------------------------
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("evaluation_log.log", encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
aclient = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# --------------------------------------------------------------------------
# [Class] ìŒì•… ì¶”ì²œ ì‹œìŠ¤í…œ í†µí•© í‰ê°€ê¸° (5ëŒ€ KPI)
# --------------------------------------------------------------------------
class MusicRecommendationEvaluator:
    def __init__(self):
        try:
            auth_manager = SpotifyClientCredentials()
            self.sp = spotipy.Spotify(auth_manager=auth_manager)
            logger.info("âœ… Spotify API Connected.")
        except Exception as e:
            logger.error(f"âŒ Spotify Connection Failed: {e}")
            self.sp = None
            
        self.diversity_pool = [] 

    def _safe_parse_json(self, json_str):
        try:
            if isinstance(json_str, dict) or isinstance(json_str, list):
                return json_str
            clean_str = json_str.replace("```json", "").replace("```", "").strip()
            start = clean_str.find('[')
            end = clean_str.rfind(']')
            if start != -1 and end != -1:
                clean_str = clean_str[start : end + 1]
            return json.loads(clean_str)
        except:
            return None

    def _extract_text_for_embedding(self, parsed_data):
        try:
            if isinstance(parsed_data, list) and len(parsed_data) > 0:
                return parsed_data[0].get('recommendation_meta', {}).get('reasoning', '')
            return ""
        except:
            return ""
            
    def _extract_track_info_str(self, parsed_data):
        try:
            if isinstance(parsed_data, list) and len(parsed_data) > 0:
                info = parsed_data[0].get('track_info', {})
                artist = info.get('artist_name', 'Unknown')
                title = info.get('track_title', 'Unknown')
                return f"{artist} - {title}"
            return "Parsing Failed"
        except:
            return "Error"

    # ======================================================================
    # KPI 1. ì •í™•ì„± (Accuracy)
    # ======================================================================
    async def evaluate_accuracy(self, row, output_data):
        criteria = row['Evaluation Criteria']
        reasoning_text = self._extract_text_for_embedding(output_data)
        
        if not reasoning_text:
            return 0, 0

        # (A) Math
        score_math = 0
        try:
            resp = await aclient.embeddings.create(
                input=[criteria, reasoning_text], 
                model="text-embedding-3-small"
            )
            vec1 = resp.data[0].embedding
            vec2 = resp.data[1].embedding
            sim = cosine_similarity([vec1], [vec2])[0][0]
            score_math = max(0, sim * 100)
            
            # [ë””ë²„ê¹…] ì ìˆ˜ê°€ ë‚®ìœ¼ë©´ ì´ìœ  í™•ì¸ìš© ë¡œê·¸
            if score_math < 40:
                logger.debug(f"[Low Math] Criteria: {criteria[:30]}... vs Reasoning: {reasoning_text[:30]}...")
        except Exception:
            pass

        # (B) Logic
        system_prompt = """
        ë‹¹ì‹ ì€ 'ìŒì•… ì¶”ì²œ í’ˆì§ˆ í‰ê°€ê´€'ì…ë‹ˆë‹¤. 
        ì‚¬ìš©ìì˜ ìš”êµ¬ì‚¬í•­(Criteria)ê³¼ AIì˜ ì¶”ì²œ ê²°ê³¼(Output)ë¥¼ ë¹„êµí•˜ì—¬ ì ìˆ˜ë¥¼ ë§¤ê¸°ì„¸ìš”.
        [ì±„ì  ê¸°ì¤€ 0~100ì ]
        1. Context ì í•©ì„±
        2. Preference ë°˜ì˜
        3. Conflict í•´ê²°
        [ì¶œë ¥ í˜•ì‹ (JSON)]
        { "score": 85, "reason": "..." }
        """
        
        context_str = f"Location: {row['Location']}, Goal: {row['Goal']}, Pref: {row['User Pref']}"
        user_msg = f"Criteria: {criteria}\nUser Input: {context_str}\nOutput: {json.dumps(output_data, ensure_ascii=False)}"
        
        score_logic = 0
        try:
            resp = await aclient.chat.completions.create(
                model="gpt-4o", 
                messages=[{"role":"system", "content":system_prompt}, {"role":"user", "content":user_msg}], 
                response_format={"type": "json_object"},
                temperature=0
            )
            eval_res = json.loads(resp.choices[0].message.content)
            score_logic = eval_res.get('score', 0)
        except Exception:
            pass

        return score_math, score_logic

    # ======================================================================
    # KPI 2. ì•ˆì •ì„± (Stability)
    # ======================================================================
    def evaluate_system_stability(self, parsed_data):
        if parsed_data is None: return 0 
        if not isinstance(parsed_data, list) or len(parsed_data) == 0: return 0 
        required = ["recommendation_meta", "track_info", "target_audio_features"]
        if all(key in parsed_data[0] for key in required):
            return 1 
        return 0

    # ======================================================================
    # KPI 3. ê²€ìƒ‰ ì„±ê³µë¥  (Search Success)
    # ======================================================================
    def evaluate_search_success(self, parsed_data):
        if not self.evaluate_system_stability(parsed_data): return 0
        
        try:
            info = parsed_data[0]['track_info']
            title = info.get('track_title', '').strip()
            artist = info.get('artist_name', '').strip()

            if not title or not artist or "unknown" in title.lower(): return 0
            if self.sp is None: return 1 

            # 1ì°¨ ì‹œë„ (ì—„ê²©)
            q_strict = f"track:{title} artist:{artist}"
            res = self.sp.search(q=q_strict, type='track', limit=1)
            if len(res['tracks']['items']) > 0: return 1 
            
            # 2ì°¨ ì‹œë„ (ëŠìŠ¨)
            q_loose = f"{title} {artist}"
            res_loose = self.sp.search(q=q_loose, type='track', limit=1)
            if len(res_loose['tracks']['items']) > 0: return 1
            
    
            return 0 
        except:
            return 0

# ======================================================================
    # KPI 4. ì¼ê´€ì„± (Consistency) - [íƒœê·¸ ë‚´ìš© ë¹„êµ]
# ======================================================================
    async def evaluate_consistency(self, inputs, first_parsed_data):
        """
        ë™ì¼ ì…ë ¥ì— ëŒ€í•´ Agentê°€ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œ 'Primary Tag'ë¥¼ ë‚´ë†“ëŠ”ì§€ í‰ê°€ (3íšŒ)
        - 1íšŒ: ì´ë¯¸ ì‹¤í–‰í•œ ê²°ê³¼(first_parsed_data) ì‚¬ìš©
        - 2,3íšŒ: ì¶”ê°€ ì‹¤í–‰í•˜ì—¬ ë¹„êµ
        """
        tags = []
        
        # 1. ì²« ë²ˆì§¸ ì‹¤í–‰ ê²°ê³¼ì—ì„œ íƒœê·¸ ì¶”ì¶œ
        if first_parsed_data:
            tag1 = first_parsed_data[0].get('recommendation_meta', {}).get('primary_tag', 'error')
            tags.append(tag1)
        else:
            tags.append("error_1")

        # 2. ë‘ ë²ˆ ë” ì‹¤í–‰ (ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬)
        try:
            tasks = [run_agent_bridge(inputs) for _ in range(2)]
            results = await asyncio.gather(*tasks)
            
            for res in results:
                parsed = self._safe_parse_json(res)
                if parsed:
                    tag = parsed[0].get('recommendation_meta', {}).get('primary_tag', 'error')
                    tags.append(tag)
                else:
                    tags.append("error_run")
                    
        except Exception as e:
            logger.error(f"Consistency Check Error: {e}")
            return 0.0

        # 3. ë¹ˆë„ ë¶„ì„ (ê°€ì¥ ë§ì´ ë‚˜ì˜¨ íƒœê·¸ê°€ ì „ì²´ì˜ ëª‡ %ì¸ê°€?)
        # ì˜ˆ: ['A', 'A', 'B'] -> 'A'ê°€ 2ë²ˆ -> 2/3 = 0.66
        # ì˜ˆ: ['A', 'B', 'C'] -> 'A'ê°€ 1ë²ˆ -> 1/3 = 0.33
        
        if not tags: return 0.0
        
        from collections import Counter
        counts = Counter(tags)
        most_common_count = counts.most_common(1)[0][1] # ê°€ì¥ ë§ì´ ë‚˜ì˜¨ íšŸìˆ˜
        
        score = most_common_count / len(tags) # (ìµœë¹ˆê°’ / ì „ì²´ ì‹œë„ íšŸìˆ˜)
        
        # [ë””ë²„ê¹… ë¡œê·¸] íƒœê·¸ê°€ ì–´ë–»ê²Œ ë‚˜ì™”ëŠ”ì§€ í™•ì¸
        if score < 1.0:
            logger.info(f"â„¹ï¸ Consistency Diff: {tags}")
            
        return score
    
# ======================================================================
    # KPI 5. ë‹¤ì–‘ì„± (diversity) 
# ======================================================================

    def record_diversity(self, parsed_data):
        if parsed_data:
            t = parsed_data[0].get('track_info', {}).get('track_title', 'unknown')
            self.diversity_pool.append(t)

    def calculate_diversity(self):
        if not self.diversity_pool: return 0.0
        return (len(set(self.diversity_pool)) / len(self.diversity_pool)) * 100

# --------------------------------------------------------------------------
# [Main] ì‹¤í–‰
# --------------------------------------------------------------------------
async def main():
    current_dir = os.path.dirname(os.path.abspath(__file__))
    csv_path = os.path.join(current_dir, "evaluation_set_v2_criteria.csv")
    
    if not os.path.exists(csv_path):
        print("âŒ í‰ê°€ì…‹ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    df = pd.read_csv(csv_path)
    evaluator = MusicRecommendationEvaluator()
    results = []
    
    print(f"\nğŸš€ 5ëŒ€ KPI í‰ê°€ ì‹œì‘ (ì´ {len(df)}ê°œ ì‹œë‚˜ë¦¬ì˜¤)")
    print("-" * 70)

    for idx, row in df.iterrows():
        inputs = {
            "location": row['Location'], "decibel": row['Decibel'],
            "goal": row['Goal'], "user_pref": row['User Pref'],
            "user_artist": row.get('User Artist', None)
        }
        
        print(f"â–¶ [{idx+1}/{len(df)}] ID {row.get('ID', idx)} ({row['Location']}) ...", end=" ")

        # 1. Agent ì‹¤í–‰
        raw_out = await run_agent_bridge(inputs)
        parsed = evaluator._safe_parse_json(raw_out)
        
        # 2. KPI ì¸¡ì •
        s_math, s_logic = await evaluator.evaluate_accuracy(row, parsed)
        final_acc = (s_math * 0.3) + (s_logic * 0.7)
        s_stability = evaluator.evaluate_system_stability(parsed)
        s_search = evaluator.evaluate_search_success(parsed)
        
        s_consist = 1.0 #ê¸°ë³¸ê°’
        if idx % 5 == 0: 
            # ì²« ë²ˆì§¸ ê²°ê³¼(parsed)ë¥¼ í¬í•¨í•´ì„œ ë¹„êµí•˜ë„ë¡ ìˆ˜ì •
            s_consist = await evaluator.evaluate_consistency(inputs, parsed)
        evaluator.record_diversity(parsed)

        # 3. í• ë£¨ì‹œë„¤ì´ì…˜ ë° íŠ¸ë™ ì •ë³´
        track_info_str = evaluator._extract_track_info_str(parsed)
        hallucinated_track = ""
        
        # ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ë¹¨ê°„ìƒ‰ ê°•ì¡° ì¶œë ¥ (ANSI Code)
        RED = "\033[91m"
        RESET = "\033[0m"
        
        if s_search == 0 and s_stability == 1:
            hallucinated_track = track_info_str
            print(f"{RED}âŒ Hallucination: {hallucinated_track}{RESET}", end=" ")
        
        # ê²°ê³¼ ì €ì¥
        results.append({
            "ID": row.get('ID', idx),
            "Context": f"{row['Location']}-{row['Goal']}",
            "Score_Total_Accuracy": round(final_acc, 1),
            "Score_Accuracy_Logic": s_logic,          # ğŸ‘ˆ ìš”ì²­í•˜ì‹  Logic ì ìˆ˜ ì¹¼ëŸ¼
            "Score_Accuracy_Math": round(s_math, 1),  # ğŸ‘ˆ ìš”ì²­í•˜ì‹  Math ì ìˆ˜ ì¹¼ëŸ¼
            "Score_Stability": s_stability,             
            "Score_SearchSuccess": s_search,          # ê°œë³„ ì„±ê³µ ì—¬ë¶€ (0 or 1)
            "Score_Consistency": s_consist,
            "Hallucination_Track": hallucinated_track, 
            "Output_Reasoning": evaluator._extract_text_for_embedding(parsed),
            "Recommended_Track": track_info_str
        })
        
        if not hallucinated_track:
            print(f"âœ… Acc:{final_acc:.0f}")

    # 4. ìµœì¢… ì§‘ê³„ ë° ì „ì²´ ì„±ê³µë¥  ê³„ì‚°
    res_df = pd.DataFrame(results)
    
    # ë‹¤ì–‘ì„± ê³„ì‚°
    diversity = evaluator.calculate_diversity()
    res_df['Score_Diversity'] = round(diversity, 1)

    # â˜… [ìš”ì²­í•˜ì‹  ê¸°ëŠ¥] ì „ì²´ ê²€ìƒ‰ ì„±ê³µë¥  ë¹„ìœ¨ ì¹¼ëŸ¼ ì¶”ê°€ (ëª¨ë“  í–‰ì— ë™ì¼í•œ ê°’ ì €ì¥)
    # (ì„±ê³µí•œ íšŸìˆ˜ / ì „ì²´ íšŸìˆ˜) * 100
    overall_search_rate = res_df['Score_SearchSuccess'].mean() * 100
    res_df['Overall_Search_Success_Rate'] = f"{overall_search_rate:.1f}%" # ğŸ‘ˆ í•œëˆˆì— ë³´ëŠ” ì„±ê³µë¥ 

    # ì½˜ì†” ë¦¬í¬íŠ¸
    print("\n" + "="*40)
    print("ğŸ†  FINAL 5-KPI REPORT  ğŸ†")
    print("="*40)
    print(f"1. ì •í™•ì„± (Accuracy)       : {res_df['Score_Total_Accuracy'].mean():.1f}ì ")
    print(f"   - Logic Avg             : {res_df['Score_Accuracy_Logic'].mean():.1f}ì ")
    print(f"   - Math Avg              : {res_df['Score_Accuracy_Math'].mean():.1f}ì ")
    print(f"2. ì•ˆì •ì„± (Stability)      : {res_df['Score_Stability'].mean()*100:.1f}%")
    print(f"3. ê²€ìƒ‰ ì„±ê³µë¥  (Success)    : {overall_search_rate:.1f}% (Total Ratio)") # ì½˜ì†”ì—ë„ í‘œì‹œ
    print(f"4. ì¼ê´€ì„± (Consistency)    : {res_df['Score_Consistency'].mean():.2f}")
    print(f"5. ë‹¤ì–‘ì„± (Diversity)      : {diversity:.1f}%")

    output_path = os.path.join(current_dir, "final_kpi_report.csv")
    res_df.to_csv(output_path, index=False, encoding="utf-8-sig")
    print(f"\nâœ… ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {output_path}")

if __name__ == "__main__":
    asyncio.run(main())